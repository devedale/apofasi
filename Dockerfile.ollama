# Dockerfile personalizzato per Ollama con LogPPT integrato
FROM ollama/ollama:latest

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    git \
    curl \
    bash \
    && rm -rf /var/lib/apt/lists/*

# Clone LogPPT repository
RUN git clone https://github.com/LogIntelligence/LogPPT.git /root/LogPPT

# Install only essential Python dependencies
# Use apt packages to avoid PEP 668 restrictions on system-wide pip installs
RUN apt-get update && apt-get install -y \
    python3-requests \
    python3-flask \
    && rm -rf /var/lib/apt/lists/*

# Copy all Modelfiles for LogPPT
COPY Modelfile.logppt /root/LogPPT/Modelfile.logppt
COPY Modelfile.logppt.fast /root/LogPPT/Modelfile.logppt.fast
COPY Modelfile.template_extractor /root/LogPPT/Modelfile.template_extractor
COPY Modelfile.roberta /root/LogPPT/Modelfile.roberta

# Set working directory to LogPPT
WORKDIR /root/LogPPT

# Create startup script that sets up LogPPT model in Ollama
RUN echo '#!/bin/bash\n\
echo "🚀 Starting Ollama with LogPPT integration..."\n\
cd /root/LogPPT\n\
\n\
# Start Ollama in background\n\
ollama serve &\n\
OLLAMA_PID=$!\n\
\n\
# Wait for Ollama API to be ready (poll)\n\
echo "⏳ Waiting for Ollama to be ready..."\n\
for i in {1..60}; do\n\
  if curl -sSf http://localhost:11434/api/tags >/dev/null; then\n\
    echo "✅ Ollama is ready"; break;\n\
  fi;\n\
  sleep 1;\n\
done\n\
\n\
# Create all LogPPT models if missing\n\
echo "📥 Setting up LogPPT models in Ollama..."\n\
\n\
# Create logppt-parser model\n\
if ! ollama list | grep -q "^logppt-parser\\b"; then\n\
  echo "Creating logppt-parser model..."\n\
  ollama create logppt-parser -f Modelfile.logppt || true\n\
fi\n\
\n\
# Create logppt-fast model\n\
if ! ollama list | grep -q "^logppt-fast\\b"; then\n\
  echo "Creating logppt-fast model..."\n\
  ollama create logppt-fast -f Modelfile.logppt.fast || true\n\
fi\n\
\n\
# Create template-extractor model\n\
if ! ollama list | grep -q "^template-extractor\\b"; then\n\
  echo "Creating template-extractor model..."\n\
  ollama create template-extractor -f Modelfile.template_extractor || true\n\
fi\n\
\n\
# Create roberta-parser model\n\
if ! ollama list | grep -q "^roberta-parser\\b"; then\n\
  echo "Creating roberta-parser model..."\n\
  ollama create roberta-parser -f Modelfile.roberta || true\n\
fi\n\
\n\
# List models to verify\n\
echo "🔍 Available models:"\n\
ollama list\n\
\n\
# Keep container running\n\
echo "✅ LogPPT + Ollama ready! Use: ollama run logppt-parser"\n\
wait $OLLAMA_PID' > /root/start.sh && \
chmod +x /root/start.sh

# Expose Ollama port
EXPOSE 11434

# Override default entrypoint from base image to run our startup script
ENTRYPOINT ["/bin/bash","-lc"]
CMD ["/root/start.sh"]
